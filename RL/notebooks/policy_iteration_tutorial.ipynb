{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8390b455c16d8249ec8600c8e6045bb",
     "grade": false,
     "grade_id": "cell-e52b1d818caf1ef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![Banner](Banner.jpg)\n",
    "\n",
    "# Evaluación de MDPs utilizando Iteración de Políticas\n",
    "\n",
    "En este tutorial vamos a implementar el primer método de solución para los Procesos de Decisión de Markov (MDPs). El método a implementar es la iteración de políticas, la cual está basada en la fórmula: \n",
    "\n",
    "$$\n",
    "V_{0}^\\pi(s) = 0 \\\\\n",
    "V_{k+1}^\\pi(s) \\leftarrow \\sum_{s'} T(s, \\pi(s), s')[R(s, \\pi(s), s') + \\gamma V_k^\\pi(s')]\n",
    "$$\n",
    "\n",
    "La solución de los MDPs se basa en poder dar un valor a cada uno de los estados a partir de una política dada $\\pi$ (siguiendo la fórmula) para ayudar al agente a llegar al objetivo del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "017b3763addf25f8de756a5f0469c644",
     "grade": false,
     "grade_id": "cell-2b119bd8c8b47b8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Definición del ambiente\n",
    "\n",
    "Para poder resolver los MDPs, necesitamos un ambiente. Como ejemplo reutilizaremos el ambiente de Gridworld creado en los tutoriales anteriores.\n",
    "\n",
    "Para tener encuenta la función de ruido, vamos a definir la función `get_possible_states` a la definición del MDP, la función retorna la probabilidad de pasar a un estado `s'` desde un estado `s` ejecutando la acción `a`. Adicionalmente, junto con la probabilidad se retorna el estado de llegada `s'`. Vamos a definir el ruido para nuestro ambiente que con probabilidad de 0.8 ejecuta la acción `a`, con probabilidad de 0.1 ejecuta la acción a la izquierda de `a` y con probabilidad de 0.1 ejecuta la acción a la derecha de `a`. Dentro de esta funcion usamos la función `get_action_index`, una función auxiliar para poder calcular fácilmente las acciones izquierda y derecha de la acción dada.\n",
    "\n",
    "Finalmente debemos definir la acción `simulate_action` que se comporta como la función `do_action` sin generar el cambio en el estado actual del ambiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "908b0a49318894e208f51ef0ac4ff058",
     "grade": false,
     "grade_id": "cell-1f5cc08315144e8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10657c4866eab3f24685c6ca805f860",
     "grade": false,
     "grade_id": "cell-48077256dc7eb43b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementación del algoritmo de iteración de políticas\n",
    "\n",
    "De la misma forma que en los tutoriales anteriores, vamos a definir el algoritmo de solución de iteración de políticas incrementalmente, sobre el código de base a continuación y dando la descripción de cada una de las funciones y sus casos de prueba progresivamente.\n",
    "\n",
    "#### Creación del agente \n",
    "\n",
    "Implemente la classe `PolicyIteration` que define cinco atributos. \n",
    "Igual que con `ValueIteration` tenemos los atributos:\n",
    "- `mdp` que corresponde al MDP a resolver (e.g., Gridworld)\n",
    "- `discount` que corresponde al factor de descuento a utilizar.\n",
    "- `iterations` que corresponde a el número de iteraciones a realizar\n",
    "- `values` que corresponde a un mapa con los valores calculados para los estados del MDP. Los estados se definen como una tupla de los valores posibles del estado. En el caso de Gridworld, la tupla es la posición de cada casilla. Inicialmente definiremos el mapa como un mapa vacío, el cual poblaremos con los estados descubiertos durante cada iteración.\n",
    "\n",
    "Adicionalmente debemos agregar el atributo:\n",
    "- `policy` que lleva la política calculada. Este atributo se define como un mapa que para cada estado del ambiente tiene la acción a ejecutar. el atributo se debe inicializar con una política aleatoria (únicamente para las casillas válidas, las casillas prohibidas deben tener una política `None`).\n",
    "\n",
    "Al momento de crear la clase `PolicyIteration`, esta debe recibir por parámetro, un `MDP`, el valor de descuento `discount` (inicializado por defecto en 0.9 si no se pasa ningún valor) y la cantidad de iteraciones a ejecutar `iterations` (con un valor de 64 por defecto).\n",
    "\n",
    "Tenga en cuenta que la técnica de iteración de políticas se define en dos partes, la evaluación de la política `policy_evaluation` y la mejora de la política `policty_improvement`, definidas como las dos funciones principales de la clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25575f1303fdb7e2e7d33d790b2e2b2a",
     "grade": false,
     "grade_id": "cell-e6bc7b2a369747c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Definición de las librerías a utilizar\n",
    "\n",
    "import random\n",
    "\n",
    "#PolicyIteration\n",
    "class PolicyIteration():\n",
    "    #1\n",
    "    def __init__(self, mdp:Gridworld, discount:float =0.9, iterations:int =64):\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_policy(self, state:tuple[int,int]) -> str:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_value(self, state:tuple[int,int]) -> float:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_action(self, state:tuple[int,int]) -> float:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def compute_new_action(self, state:tuple[int,int]) -> str:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def value_evaluation(self, state:tuple[int,int], action:str) -> float:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def compute_new_value(self, state:tuple[int,int]) -> float:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def policy_convergence(self, new_policy:dict[tuple[int,int],float]) -> bool:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def policy_improvement(self) -> tuple[bool, dict[tuple[int,int],float]]:\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run_policy_iteration(self) -> tuple[dict[tuple[int,int],float], dict[tuple[int,int],str]]:\n",
    "        done = False\n",
    "        i = 1\n",
    "        policy = {}\n",
    "        while not done and i <= self.iterations:\n",
    "            done, policy = self.policy_improvement()\n",
    "            i += 1\n",
    "        if done:\n",
    "            print(f\"La política converge en {i} iteraciones\")\n",
    "            print(policy)\n",
    "        return self.values, self.policy        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87a7f806bc5e84e9e8dabcc55db07321",
     "grade": false,
     "grade_id": "cell-c1534334fbb97941",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a457720b114e063466938a819297f70d",
     "grade": true,
     "grade_id": "cell-f076f5b183b66020",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas estructura del agente\n",
    "### BEGIN TESTS\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "try:\n",
    "    a.mdp\n",
    "except:\n",
    "    raise Exception(\"El atributo mdp no está definido\")\n",
    "try:\n",
    "    a.discount\n",
    "except:\n",
    "    raise Exception(\"El atributo discount no está definido\")\n",
    "try:\n",
    "    a.iterations\n",
    "except:\n",
    "    raise Exception(\"El atributo iterations no está definido\")\n",
    "\n",
    "try:\n",
    "    a.values\n",
    "except:\n",
    "    raise Exception(\"El atributo values no está definido\")\n",
    "\n",
    "assert a.mdp == gridworld, \"El valor de mdp no se inicializa correctamente al MDP dado por parámetro\"\n",
    "assert a.discount == 0.8, \"El valor de discount no se asigna al valor pasado por parámetro 0.8\"\n",
    "assert a.iterations == 50, \"El valor de iterations no se asigna al valor pasado por parámetro 50\"\n",
    "\n",
    "a = PolicyIteration(gridworld)\n",
    "assert a.discount == 0.9, \"El valor de discount no se esta asignando por defecto a 0.9\"\n",
    "assert a.iterations == 64, \"El valor de iterations no se asigna al valor pasado por parámetro 64\"\n",
    "\n",
    "assert a.values == {}, \"El valor de values no es vacio para comenzar\"\n",
    "assert type(a.policy) == dict, \"La política se debe inicializar como un mapa, con una acción aleatoria para cada estado\"\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1a11e4aa3358a10cc6fa17fd5998b44",
     "grade": false,
     "grade_id": "cell-b0a864b3f319281c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Política del agente\n",
    "\n",
    "Implemente la función `get_policy` que recibe un estado por parámetro y retorna la acción (política) actuales para dicho estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69ce5fa8c834e2057a74197985d62b41",
     "grade": true,
     "grade_id": "cell-2cf632db9310baca",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas política\n",
    "\n",
    "import inspect\n",
    "### BEGIN TESTS\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "try:\n",
    "    a.get_policy\n",
    "except:\n",
    "    print(\"La función get_policy no está definida\")\n",
    "\n",
    "assert len(inspect.signature(a.get_policy).parameters) == 1, \"La función get_policy no recibe un parámetro\"\n",
    "assert a.get_policy((2,2)) == None, \"Las casillas prohibidas no deberían tener una política asignada, las acciones en estos estados deben ser None\"\n",
    "assert a.get_policy((0,3)) == 'exit', \"Las casillas de salida deben tener una política de salida, dado que es la única acción posible en esas casillas\"\n",
    "assert a.get_policy((0,2)) in [\"up\", \"right\", \"down\", \"left\"], \"La política en los estados debe ser una de las acciones posibles para los estados\"\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7517dbae38c5ea883a5fc1ff94a45dba",
     "grade": false,
     "grade_id": "cell-c672b6141ff26d04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Valor de estados\n",
    "\n",
    "Implemente la función `get_value` que recibe un estado como parámetro y retorna el valor correspondiente para dicho estado. Si el estado no ha sido visitado, supondremos que su valor es 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a991d7626d88c5ebbf45d3ab0ae1f37d",
     "grade": true,
     "grade_id": "cell-cb79fdf23dab7d8d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de get_value\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.get_value\n",
    "except:\n",
    "    print(\"La función get_value no está definida\")\n",
    "\n",
    "a.values[(0,3)] = 1\n",
    "a.values[(1,3)] = -1\n",
    "\n",
    "assert a.get_value((0,3)) == 1, f\"la función get_value no esta retornando el valor guardado en el mapa responde {a.get_value((0,3))} y no 1\"\n",
    "assert a.get_value((0,0)) == 0, f\"la función get_value no devuelve el valor de 0 para los estados no visitados, devuelve {a.get_value((0,0))}\"\n",
    "\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "383058dd90f22877ce9e84357218f3fc",
     "grade": false,
     "grade_id": "cell-1eff1598db16f057",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Evaluación de valores \n",
    "\n",
    "Defina la función `value_evaluation` tiene como propósito calcular el valor de un estado (sin modificar el atributo de valores), dada una acción.\n",
    "Esta función recibe por parámetro un estado y una acción a ejecutar en el estado y retorna el valor calculado para dicho estado.  \n",
    "\n",
    "Note que para poder realizar este cálculo requerimos la nueva función del ambiente `get_possible_states`. La nueva función recibe la acción a ejecutar para el estado a evaluar del ambiente y retorna una lista con las probabilidades de transiciones entre los estados, una lista de recompensas y una lista de los estados de llegada del estado actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f810b1a14423c0e20403389c6dd61ed5",
     "grade": true,
     "grade_id": "cell-76223d66b87c5e10",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de value_evaluation\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.value_evaluation\n",
    "except:\n",
    "    print(\"La función value_evaluation no está definida\")\n",
    "\n",
    "a.values[(3,0)] = 0.5\n",
    "a.values[(2,1)] = 1\n",
    "a.values[(3,2)] = 0.5\n",
    "\n",
    "value_up = a.value_evaluation((3,1), 'up')\n",
    "value_down = a.value_evaluation((3,1), 'down')\n",
    "assert value_up > value_down, f\"la función value_evaluation no esta calculando el valor correctamente los valores segun la fórmula ((3,1), up) debe ser 0.7200000000000002 y no {value_up}\"\n",
    "\n",
    "\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20022db25ef9903cf3e031551a86d140",
     "grade": false,
     "grade_id": "cell-df267449580df2bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Cálculo de valor \n",
    "\n",
    "Defina la función `compute_new_value` que de forma similar a `value_evaluation` calcula el valor para el estado. La diferencia con la función anterior, es que `compute_new_value` calcula el valor máximo de todas las acciones posibles, dado un estado y no solo el valor de una única acción. \n",
    "Esta función recibe un estado como parámetro y calcula el nuevo valor para el estado siguiendo la fórmula de iteración de políticas. Esta función calcula el nuevo valor para el estado actual del agente (`s`) a partir de los estados, las recompensas y los valores de los posibles estados de llegada (`s'`) de acuerdo a la función de transición (o ruido), obteniendo el valor máximo de todas las posibles acciones en el estado de entrada.\n",
    "\n",
    "Adicional al valor máximo, esta función debe retornar la acción que nos lleva a ese máximo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d693bb07432b4ac972c4a787e032662f",
     "grade": true,
     "grade_id": "cell-003ce6d881601b31",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de compute_new_value\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.compute_new_value\n",
    "except:\n",
    "    print(\"La función compute_new_value no está definida\")\n",
    "\n",
    "a.values[(3,0)] = 0.5\n",
    "a.values[(2,1)] = 1\n",
    "a.values[(3,2)] = 0.5\n",
    "\n",
    "value, action1 = a.compute_new_value((3,1))\n",
    "assert abs(value - 0.7200000000000002) < 0.000001, f\"la función compute_new_value no esta calculando el valor correctamente obtiene el valor {value} y no 0.7200000000000002\"\n",
    "assert action1 == 'up', f\"la función compute_new_value no esta calculando la acción del mejor valor correctamente, obtiene {action1} y no up\"\n",
    "value, action2 = a.compute_new_value((0,1))\n",
    "assert abs(value - 0.0) < 0.000001, f\"la función compute_new_value no esta calculando el valor correctamente obtiene el valor {value} y no 0.0\"\n",
    "assert action2 == 'left', f\"la función compute_new_value no esta calculando la acción del mejor valor correctamente, obtiene {action2} y no left\"\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ead54956eecca7555517aa541642d46",
     "grade": false,
     "grade_id": "cell-37617b789ac73483",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Acción para un estado \n",
    "\n",
    "Implemente la función `get_action` que retorna la mejor acción a realizar para un estado dado por parámetro. Está acción corresponde a la acción actual de la política.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45c1380fa0c427db5f54d8871c697f10",
     "grade": true,
     "grade_id": "cell-40627b3922ae7c01",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de get_action\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.get_action\n",
    "except:\n",
    "    print(\"La función get_action no está definida\")\n",
    "\n",
    "\n",
    "assert a.get_action((2,2)) == None, f\"la función get_action debe retornar None para las casillas prohibidas, retorna {a.get_action((2,2))}\"\n",
    "assert a.get_action((2,3)) == a.policy[(2,3)], f\"la función get_action debe retornar la acción correspondiente a la política actual\"\n",
    "\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27e9c69fb135366b954a3ee617cf7bcc",
     "grade": false,
     "grade_id": "cell-3d55f604f5ad785f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Calculo de acciones\n",
    "\n",
    "Implemente la función `compute_new_action` que retorna la nueva mejor acción a realizar luego de ejecutar el cálculo del nuevo valor para un estado. La función recibe un estado como parámetro y retorna la mejor acción a ejecutar para ese estado (actualizando la política).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "854e579941b71d1f6589bfc06e5a1542",
     "grade": true,
     "grade_id": "cell-7e7bb415147c7910",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de compute_new_action\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.compute_new_action\n",
    "except:\n",
    "    print(\"La función compute_new_action no está definida\")\n",
    "\n",
    "a.values[(3,0)] = 0.5\n",
    "a.values[(2,1)] = 1\n",
    "a.values[(3,2)] = 0.5\n",
    "a.policy[(3,1)] = 'right'\n",
    "\n",
    "assert a.compute_new_action((2,2)) == None, f\"la función compute_new_action no debe variar para las casillas prohibidas\"\n",
    "assert a.compute_new_action((0,3)) == 'exit', f\"la función compute_new_action no debe variar para las casillas de salida\"\n",
    "\n",
    "assert a.compute_new_action((3,1)) == 'up', f\"la función compute_new_action debe retornar la acción correspondiente a la política actual\"\n",
    "\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c0d76a12a698c27861f99b30b5dbd81",
     "grade": false,
     "grade_id": "cell-eae49ce7468647f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Evaluación de convergencia de la política\n",
    "\n",
    "Implemente la función `policy_convergence` recibe la nueva política calculada como parámetro y evalúa si existió algún cambio. en caso de tener un cambio con la política actual, la función retorna `True`, de lo contrario retorna `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e7e40f9d3152f772be9442a32627d1d",
     "grade": true,
     "grade_id": "cell-1a78be75f68995ee",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de policy_evaluation\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.policy_convergence\n",
    "except:\n",
    "    print(\"La función policy_convergence no está definida\")\n",
    "\n",
    "for i in range(gridworld.nrows):\n",
    "    for j in range(gridworld.ncols):\n",
    "        a.policy[(i,j)] = 'down'\n",
    "a.policy[(1,1)] = ''\n",
    "a.policy[(2,2)] = ''\n",
    "a.policy[(0,3)] = 'exit'\n",
    "a.policy[(1,3)] = 'exit'\n",
    "\n",
    "policy1 = a.policy\n",
    "policy2 = {}\n",
    "for i in range(gridworld.nrows):\n",
    "    for j in range(gridworld.ncols):\n",
    "        policy2[(i,j)] = random.choice(['up', 'right', 'down', 'left'])\n",
    "policy2[(1,1)] = ''\n",
    "policy2[(2,2)] = ''\n",
    "policy2[(0,3)] = 'exit'\n",
    "policy2[(1,3)] = 'exit'\n",
    "\n",
    "\n",
    "\n",
    "assert a.policy_convergence(policy1) == False, f\"la función policy_evaluation no retorna False si no hay cambio en la política\"\n",
    "assert a.policy_convergence(policy2) == True, f\"la función policy_evaluation no retorna True si hay un cambio en la política\"\n",
    "\n",
    "\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe8a95f84442186817548e980f04d328",
     "grade": false,
     "grade_id": "cell-359ce9eaa9c80d09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Mejora de políticas\n",
    "\n",
    "Implemente la función `policy_improvement` encargada de ejecutar la iteración de políticas en tres pasos. \n",
    "1. Primero se realiza el cálculo de los nuevos valores. esto quiere decir que para cada uno de los estados del ambiente se calcula su nuevo valor utilizando la política actual.\n",
    "2. Segundo, para los nuevos valores se revisa la mejora de la política calculando la mejor acción posible para cada uno de los estados (usando función `compute_new_action`). \n",
    "3. Tercero, se evalúa la política calculada de las nuevas acciones en el paso anterior, actualizando la política si se encontraron mejores acciones. Si no hay una mejor acción, función debe retornar la política calculada y un indicador que hay convergencia para detener la iteración.\n",
    "\n",
    "La función debe retornar `True` si la política converge y `False` si no lo hace, junto con la política calculada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c60c72bd572097b66e1bb060d221b4f0",
     "grade": true,
     "grade_id": "cell-c62dd7acb84b1ac2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de policy_improvement\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 50)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.policy_improvement\n",
    "except:\n",
    "    raise Exception(\"La función policy_improvement no está definida\")\n",
    "\n",
    "\n",
    "a.values[(3,0)] = 0.5\n",
    "a.values[(2,1)] = 1\n",
    "a.values[(3,2)] = 0.5\n",
    "for i in range(gridworld.nrows):\n",
    "    for j in range(gridworld.ncols):\n",
    "        a.policy[(i,j)] = 'down'\n",
    "a.policy[(1,1)] = ''\n",
    "a.policy[(2,2)] = ''\n",
    "a.policy[(0,3)] = 'exit'\n",
    "a.policy[(1,3)] = 'exit'\n",
    "\n",
    "res, policy = a.policy_improvement()\n",
    "assert res == False, f\"la función policy_improvement no debe estabilizarce en tan solo una iteración teniendo en cuenta la política dada\"\n",
    "assert policy[(3,1)] == 'left', f\"La política para el estado (3,1) debe cambiar de 'down' a 'left', no {policy[(3,1)]}\"\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6222db1ea1db1492c244d4540ad53b6",
     "grade": false,
     "grade_id": "cell-dd002709253b36e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "#### Ejecución del agente \n",
    "\n",
    "Finalmente definimos la función `run_policy_iteration` que no recibe ningún parámatro y ejecuta el algoritmo de solución del MDP.\n",
    "\n",
    "Esta función ejecuta el número de iteraciones dadas a la clase. Para cada una de las iteraciones se debe calcular el nuevo valor para cada uno de los estados `(i,j)` del ambiente y la nueva política. \n",
    "\n",
    "Tenga en cuenta que el cálculo de los nuevos valores se debe realizar con los valores anteriores y únicamente se deben actualizar los valores cuando se actualicen los valores para todos los estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d1c2b02bcd9a3688ba9c40de01570dd",
     "grade": true,
     "grade_id": "cell-c452a6319c180ddc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Pruebas de ejecución del agente\n",
    "\n",
    "a = PolicyIteration(gridworld, 0.8, 100)\n",
    "\n",
    "### BEGIN TESTS\n",
    "try:\n",
    "    a.run_policy_iteration\n",
    "except:\n",
    "    print(\"La función run_policy_iteration no está definida\")\n",
    "\n",
    "\n",
    "a.run_policy_iteration()\n",
    "\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
